{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7b7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"KMEANS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5850f00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------+---------------+-----------------+---------------+----------------+\n",
      "|Session_Connection_Time|Bytes Transferred|Kali_Trace_Used|Servers_Corrupted|Pages_Corrupted|WPM_Typing_Speed|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+----------------+\n",
      "|                    8.0|           391.09|              1|             2.96|            7.0|           72.37|\n",
      "|                   20.0|           720.99|              0|             3.04|            9.0|           69.08|\n",
      "|                   31.0|           356.32|              1|             3.71|            8.0|           70.58|\n",
      "|                    2.0|           228.08|              1|             2.48|            8.0|            70.8|\n",
      "|                   20.0|            408.5|              0|             3.57|            8.0|           71.28|\n",
      "|                    1.0|           390.69|              1|             2.79|            9.0|           71.57|\n",
      "|                   18.0|           342.97|              1|              5.1|            7.0|           72.32|\n",
      "|                   22.0|           101.61|              1|             3.03|            7.0|           72.03|\n",
      "|                   15.0|           275.53|              1|             3.53|            8.0|           70.17|\n",
      "|                   12.0|           424.83|              1|             2.53|            8.0|           69.99|\n",
      "|                   15.0|           249.09|              1|             3.39|            9.0|           70.77|\n",
      "|                   32.0|           242.48|              0|             4.24|            8.0|           67.93|\n",
      "|                   23.0|           514.54|              0|             3.18|            8.0|           68.56|\n",
      "|                    9.0|           284.77|              0|             3.12|            9.0|           70.82|\n",
      "|                   27.0|           779.25|              1|             2.37|            8.0|           72.73|\n",
      "|                   12.0|           307.31|              1|             3.22|            7.0|           67.95|\n",
      "|                   21.0|           355.94|              1|              2.0|            7.0|            72.0|\n",
      "|                   10.0|           372.65|              0|             3.33|            7.0|           69.19|\n",
      "|                   20.0|           347.23|              1|             2.33|            7.0|           70.41|\n",
      "|                   22.0|           456.57|              0|             1.52|            8.0|           69.35|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"11_hack_data.csv\", inferSchema=True, header=True)\n",
    "data = data.drop('Location')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10090a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dataset\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=data.columns, outputCol='features')\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6124651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "data = scaler.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c445a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "from pyspark.ml.clustering import KMeans\n",
    "kmeans = KMeans(featuresCol='scaled_features', k=2)\n",
    "kmeans = kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09d7b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------+---------------+-----------------+---------------+----------------+--------------------+--------------------+----------+\n",
      "|Session_Connection_Time|Bytes Transferred|Kali_Trace_Used|Servers_Corrupted|Pages_Corrupted|WPM_Typing_Speed|            features|     scaled_features|prediction|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+----------------+--------------------+--------------------+----------+\n",
      "|                    8.0|           391.09|              1|             2.96|            7.0|           72.37|[8.0,391.09,1.0,2...|[0.56785108466505...|         1|\n",
      "|                   20.0|           720.99|              0|             3.04|            9.0|           69.08|[20.0,720.99,0.0,...|[1.41962771166263...|         1|\n",
      "|                   31.0|           356.32|              1|             3.71|            8.0|           70.58|[31.0,356.32,1.0,...|[2.20042295307707...|         1|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+----------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the predictions\n",
    "kmeans.transform(data).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "006ebbad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|  167|\n",
      "|         0|  167|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of samples in each predicted cluster (k = 2)\n",
    "df_pred = kmeans.transform(data)\n",
    "df_pred = df_pred.groupby('prediction').count()\n",
    "df_pred.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
